"""Interactively edit or preview object tracking data generated by automatic trackers such as SORT. 

Keys: 
o/p : previous/next frame
g : jump to specific frame
s : save changes
r : revert to last saved
R : redo changes (undo revert)

Mouse:
Left click within bounding box: select bounding box. Cycle selection if multiple boxes overlap region. Selected box is shown with white border.
Left click outside bounding box: deselect.
Right click within selected bounding box: Edit ID of clicked box. Enter new id and press ENTER. Edited box is shown with orange border.
Right click within another bounding box: swap IDs of clicked box with previously selected box.


"""

import argparse
import ast
import csv
import platform
import sys

import cv2

if platform.system() == "Windows":
    import win32api  # noqa

    screen_x = win32api.GetSystemMetrics(0)
    screen_y = win32api.GetSystemMetrics(1)
elif platform.system() == "Linux":
    screen_x = 2560
    screen_y = 1440
elif platform.system() == "Darwin":
    screen_x = 1024
    screen_y = 768
else:
    screen_x = 1024
    screen_y = 768

ix, iy = -1, -1
drawing = False  # true if mouse is pressed
klasa = 0  # Klasa za nove anotacije
selected = None
update_display = True
save = False
edit_class = False


def box2yolo(box, img_shape):
    w = box[2] - box[0]
    h = box[3] - box[1]
    x = (box[0] + box[2]) / 2.0
    y = (box[1] + box[3]) / 2.0

    x = x / img_shape[1]
    w = w * 1.0 / img_shape[1]
    y = y / img_shape[0]
    h = h * 1.0 / img_shape[0]
    return box[4], x, y, w, h


def yolo2cv(res, img_shape):
    w = img_shape[1]
    h = img_shape[0]
    center_x = res[1] * w
    center_y = res[2] * h
    width = int(res[3] * w)
    height = int(res[4] * h)
    ul_x = int(center_x - width / 2)  # Upper Left corner X coord
    ul_y = int(center_y - height / 2)  # Upper left Y
    lr_x = ul_x + width
    lr_y = ul_y + height
    return ul_x, ul_y, lr_x, lr_y, res[0]


def open_yolo_annotation(file_name):
    dets = []
    with open(file_name) as ann_file:
        for row in ann_file:
            dets.append([ast.literal_eval(x) for x in row.strip().split(" ")])
    return dets


def ds2cv(res):
    return res[1], res[2], res[3], res[4], res[0]


def sort2cv(res):
    ul_x = res[1]
    ul_y = res[2]
    width = res[3]
    height = res[4]

    lr_x = ul_x + width
    lr_y = ul_y + height
    return ul_x, ul_y, lr_x, lr_y, res[0]


def put_annotations(img, boxes, det_format):
    box_colors = {0: (0, 200, 0), 1: (0, 0, 200), 7: (0, 0, 200)}
    font = cv2.FONT_HERSHEY_SIMPLEX
    for box in boxes:
        if det_format == "sort":
            temp_box = sort2cv(box)
        else:
            temp_box = ds2cv(box)
        cv2.rectangle(
            img,
            (temp_box[0], temp_box[1]),
            (temp_box[2], temp_box[3]),
            box_colors[1],
            2,
        )
        cv2.putText(
            img,
            str(temp_box[4]),
            (temp_box[0], temp_box[1]),
            font,
            0.8,
            (0, 200, 0),
            2,
            cv2.LINE_AA,
        )
    return img


def rescale_screen(im):
    dx = screen_x - im.shape[1]
    dy = screen_y - im.shape[0]
    sr = screen_x / float(screen_y)
    ir = im.shape[1] / float(im.shape[0])
    if dx >= 0 and dy >= 0:
        return im
    elif ir > sr:
        m = float(screen_x) / im.shape[1]
    else:
        m = im.shape[0] / float(screen_y)
    im = cv2.resize(im, dsize=None, fx=m, fy=m)
    return im


def open_tracking_annotation(file_name):
    dets = []
    with open(file_name) as ann_file:
        for row in ann_file:
            dets.append(
                [int(ast.literal_eval(x.strip())) for x in row.strip().split(",")]
            )
    return dets


def detect(detections, frame_no):
    boxes = [row[1:6] for row in detections if row[0] == frame_no]
    return boxes


def get_number():
    buf = ""
    while 1:
        k = cv2.waitKey(1) & 0xFF
        if ord("0") <= k <= ord("9"):
            buf += chr(k)
        elif k == 13:  # enter
            try:
                return int(buf)
            except:
                return -1
        elif k == 8:  # backspace
            try:
                buf = buf[:-1]
            except:
                pass
        elif k < 255:
            print(k)
        elif k == 27:
            return -1
        cv2.setWindowTitle("image", "Goto frame: {}".format(buf))
    try:
        return int(buf)
    except:
        return -1


def get_new_class():
    global selected
    buf = ""
    while selected is not None:
        k = cv2.waitKey(1) & 0xFF
        if ord("0") <= k <= ord("9"):
            buf += chr(k)
        elif k == 13:  # enter
            try:
                return int(buf)
            except:
                return -1
        elif k == 8:  # backspace
            try:
                buf = buf[:-1]
            except:
                pass
        elif k < 255:
            print(k)
        cv2.setWindowTitle("image", "New ID: " + buf)
    try:
        return int(buf)
    except:
        return -1


def update_class(detections, frame_no, old_class, new_class):
    existing_ids = []
    edited_frame = 0
    for i in range(len(detections)):
        if detections[i][0] > edited_frame:
            edited_frame = detections[i][0]
            j = 0
            existing_ids = []
            while i + j < len(detections) and detections[i + j][0] == edited_frame:
                existing_ids.append(detections[i + j][1])
                j += 1
        detection = detections[i]
        if (
            detection[0] >= frame_no
            and detection[1] == old_class
            and new_class not in existing_ids
        ):
            detection[1] = new_class
    return detections


def save_detections(detections, output_name):
    with open(output_name, "w", newline="\n") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=",", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in detections:
            writer.writerow(row)


def main(args):
    MAX_BUFFER = 300
    global klasa, update_display, selected, save, edit_class
    vid_fname = args.video
    cap = cv2.VideoCapture(vid_fname)
    detections = open_tracking_annotation(args.input)
    frame_no = 1
    buffered_frames = []
    buffer = []
    while cap.isOpened():
        ret, im = cap.read()
        if not ret:
            break
        buffer.append(im.copy())
        buffered_frames.append(frame_no)
        if len(buffer) > MAX_BUFFER:
            buffer.pop(0)
            buffered_frames.pop(0)
        cv2.namedWindow("image",flags=cv2.WINDOW_GUI_NORMAL)
        cv2.setWindowTitle("image", vid_fname)
        img = im.copy()
        boxes = detect(detections, frame_no)
        cv2.setMouseCallback(
            "image", probe_position, param=[boxes, img, im, detections, frame_no]
        )

        while 1:
            if update_display:
                img = im.copy()
                img = put_annotations(img, boxes, args.tracker)
                if selected is not None:
                    box = boxes[selected]
                    if edit_class:
                        cv2.rectangle(
                            img, (box[1], box[2]), (box[3], box[4]), (0, 165, 255), 2
                        )
                    else:
                        cv2.rectangle(
                            img, (box[1], box[2]), (box[3], box[4]), (255, 255, 255), 2
                        )
                img = rescale_screen(img)  # TODO: provjeri tu ili gore?
                cv2.imshow("image", img)
                cv2.setWindowTitle("image", vid_fname + " Frame: {}".format(frame_no))
                update_display = False
                while selected is not None and edit_class:
                    nc = get_new_class()
                    if (
                        selected is None
                    ):  # ako je netko deselektirao kutiju u medjuvremenu
                        edit_class = False
                        update_display = True
                        break
                    detections = update_class(
                        detections, frame_no, boxes[selected][0], nc
                    )
                    boxes = detect(detections, frame_no)
                    print(nc)
                    selected = None
                    edit_class = False
                    update_display = True

            k = cv2.waitKey(1) & 0xFF
            if k == ord("s"):  # Save
                save_detections(detections, args.input[0:-4] + "_new.txt")
            elif k == ord("r"):  # Revert to last saved
                save_detections(detections, args.input[0:-4] + "_new_redo.txt")
                print("VraÄ‡am se na zadnju snimljenu verziju")
                try:
                    detections = open_tracking_annotation(args.input[0:-4] + "_new.txt")
                except:
                    detections = open_tracking_annotation(args.input)
                boxes = detect(detections, frame_no)
                cv2.setMouseCallback(
                    "image",
                    probe_position,
                    param=[boxes, img, im, detections, frame_no],
                )
            elif k == ord("R"):  # "redo"
                try:
                    detections = open_tracking_annotation(
                        args.input[0:-4] + "_new_redo.txt"
                    )
                    print("Redo")
                except:
                    print("No redo file.")
                boxes = detect(detections, frame_no)
                cv2.setMouseCallback(
                    "image",
                    probe_position,
                    param=[boxes, img, im, detections, frame_no],
                )
            # elif k == 8:
            #     if selected is not None:
            #         del boxes[selected]
            #         selected = None
            #         save = True
            #         update_display = True
            elif k == ord("o") or k == ord("q"):
                if frame_no > 0:
                    frame_no -= 1
                drawing = False
                selected = None
                update_display = True
                if frame_no in buffered_frames:
                    im = buffer[buffered_frames.index(frame_no)]
                    boxes = detect(detections, frame_no)
                    cv2.setMouseCallback(
                        "image",
                        probe_position,
                        param=[boxes, img, im, detections, frame_no],
                    )
                else:
                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)
                    break
            elif k == ord("p") or k == ord("w"):
                frame_no += 1
                drawing = False
                selected = None
                update_display = True
                if frame_no in buffered_frames:
                    im = buffer[buffered_frames.index(frame_no)]
                    boxes = detect(detections, frame_no)
                    cv2.setMouseCallback(
                        "image",
                        probe_position,
                        param=[boxes, img, im, detections, frame_no],
                    )
                else:
                    if cap.get(cv2.CAP_PROP_POS_FRAMES) != frame_no:
                        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)
                    break
            elif k == ord("g"):  # goto frame
                new_frame_number = get_number()
                update_display = True
                if (
                    new_frame_number > 0
                ):  # and new_frame_number < cv2.CAP_PROP_FRAME_COUNT:
                    frame_no = new_frame_number
                    drawing = False
                    selected = None
                    update_display = True
                    if frame_no in buffered_frames:
                        im = buffer[buffered_frames.index(frame_no)]
                        boxes = detect(detections, frame_no)
                        cv2.setMouseCallback(
                            "image",
                            probe_position,
                            param=[boxes, img, im, detections, frame_no],
                        )
                    else:
                        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)
                        break
            elif k == 27:
                save_detections(detections, args.input[0:-4] + "_new.txt")
                cv2.destroyAllWindows()
                sys.exit(0)
        update_display = True
    save_detections(detections, args.input[0:-4] + "_new.txt")
    cv2.destroyAllWindows()


def within(point, box):
    return box[1] <= point[0] <= box[3] and box[2] <= point[1] <= box[4]


def probe_position(event, x, y, flags, param):
    global ix, iy, drawing, save, selected, update_display, edit_class
    boxes = param[0]
    detections = param[3]
    frame_no = param[4]
    if event == cv2.EVENT_LBUTTONDOWN:
        if selected is None:
            for i in range(len(boxes)):
                if within((x, y), boxes[i]):
                    # print("Within box {}".format(i))
                    selected = i
                    update_display = True
        else:
            last_selected = selected
            selected = None
            for i in range(len(boxes)):
                if i != last_selected and within((x, y), boxes[i]):
                    # print("Within box {}".format(i))
                    selected = i
            update_display = True
            ix, iy = x, y
    if event == cv2.EVENT_RBUTTONUP:
        # ako je selektirana jedna kutija, desni klik na drugu zamijeni IDove.
        if selected is not None:
            if within((x, y), boxes[selected]):
                edit_class = True
                update_display = True
            else:
                for i in range(len(boxes)):
                    if within((x, y), boxes[i]):
                        # print("Within box {}".format(i))
                        klasa1 = boxes[i][0]
                        klasa2 = boxes[selected][0]
                        detections = update_class(detections, frame_no, klasa1, 999999)
                        detections = update_class(detections, frame_no, klasa2, klasa1)
                        detections = update_class(detections, frame_no, 999999, klasa2)

                        boxes[selected][0] = klasa1
                        boxes[i][0] = klasa2

                        selected = None
                        update_display = True


if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Edit and preview object tracking data.")
    ap.add_argument("input", help="tracking data (MOT challenge data format text file output by e.g. SORT tracker)")
    ap.add_argument("video", help="path to video file.")
    ap.add_argument("--tracker", help="input format: ds - Deep SORT tracker (default), sort - SORT tracker", default="ds")
    args = ap.parse_args(sys.argv[1:])
    main(args)
